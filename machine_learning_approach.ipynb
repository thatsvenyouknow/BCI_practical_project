{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "import os\n",
    "import pywt\n",
    "from scipy.signal import welch\n",
    "\n",
    "#Machine Learning\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data_set, target_path):\n",
    "    #load subject_data one by one\n",
    "    for path in natsorted(os.listdir(data_set))[:-1]:\n",
    "        file = np.load(os.path.join(data_set,path), allow_pickle=True)\n",
    "\n",
    "        #VAR\n",
    "        np_var = partial(np.var, axis=1)\n",
    "        a, b, c = np.split(file, [55, 110], axis=1)\n",
    "        VAR = np.hstack((\n",
    "            np_var(file),\n",
    "            np_var(a),\n",
    "            np_var(b),\n",
    "            np_var(c))\n",
    "            )\n",
    "        VAR = (VAR-np.mean(VAR))/np.std(VAR) #normalize\n",
    "\n",
    "        #PSD (Welch)\n",
    "        freq, power = welch(file, fs = 250)\n",
    "        PSD = power[:,:25].flatten() #take first 25 components (~35Hz)\n",
    "        PSD = (PSD-np.mean(PSD))/np.std(PSD) #normalize\n",
    "\n",
    "        #DWT (only use approximate coefficients)\n",
    "        (aC, dC1, dC2, dC3) = pywt.wavedec(file, wavelet = \"db8\", mode='sym', level=3)\n",
    "        DWT = aC.flatten()\n",
    "        DWT = (DWT-np.mean(DWT))/np.std(DWT) #normalize\n",
    "\n",
    "        sample = np.hstack((VAR, PSD, DWT))\n",
    "        np.save(\"{}/{}\".format(target_path, os.path.basename(path)), sample)\n",
    "    #np.save(\"{}/{}\".format(target_path, os.path.basename(path)), np.load(data_set+\"/labels.npy\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ml_multi = \"C:/Users/Daydreamore/Desktop/Semester/BCI/data_ml_multi\"\n",
    "train_multi = \"C:/Users/Daydreamore/Desktop/Semester/BCI/train_multi\"\n",
    "val_multi = \"C:/Users/Daydreamore/Desktop/Semester/BCI/val_multi\"\n",
    "feature_engineering(train_multi, data_ml_multi)\n",
    "feature_engineering(val_multi, data_ml_multi)\n",
    "\n",
    "#Combine labes of train and val (we use CV for the ML part)\n",
    "labels1 = np.load(train_multi+\"/labels.npy\")\n",
    "labels2 = np.load(val_multi+\"/labels.npy\")\n",
    "labels = np.hstack((labels1, labels2))\n",
    "np.save(\"{}/{}\".format(data_ml_multi, os.path.basename(path)), labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets. \n",
    "Randomly select equal number of control trials for each participant to avoid unbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ml_multi = \"C:/Users/Daydreamore/Desktop/Semester/BCI/data_ml_multi\"\n",
    "X_train = np.array([np.load(data_ml_multi + \"/\" + path) for path in natsorted(os.listdir(data_ml_multi))[:-1]])\n",
    "Y_train = np.load(data_ml_multi+\"/\"+\"labels.npy\")\n",
    "\n",
    "#For control randomly sample 325 trials (to avoid imbalanced dataset)\n",
    "for i in range(3):\n",
    "    target_ixs = np.where(Y_train == i)\n",
    "\n",
    "    if i == 0: \n",
    "        target_ixs_shuffled = np.random.choice(target_ixs[0], size = 325, replace = False)\n",
    "        selected_samples = X_train[target_ixs_shuffled]\n",
    "        selected_labels = Y_train[target_ixs_shuffled]\n",
    "        X_train_selected = selected_samples\n",
    "        Y_train_selected = selected_labels\n",
    "    else:\n",
    "        selected_samples = X_train[target_ixs]\n",
    "        selected_labels = Y_train[target_ixs]\n",
    "        X_train_selected = np.concatenate((X_train_selected, selected_samples))\n",
    "        Y_train_selected = np.concatenate((Y_train_selected, selected_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity Check to see if dimensions are as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected.shape, Y_train_selected.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting\n",
    "Try to overfit on training data to see if the SVM can learn to tell the conditions apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "overfit = SVC()#kernel = \"linear\")\n",
    "overfit.fit(X_train_selected, Y_train_selected)\n",
    "yhat = overfit.predict(X_train_selected)\n",
    "acc_svm = accuracy_score(Y_train_selected, yhat)\n",
    "print(acc_svm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine hyperparameter search with model selection through nested cross-validation and put out winning combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_results = list()\n",
    "#Outer CV\n",
    "cv_outer = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_ix, val_ix in cv_outer.split(X_train_selected): #Splitting fault?\n",
    "    #split data\n",
    "    x_train, x_val = X_train_selected[train_ix, :], X_train_selected[val_ix, :]\n",
    "    y_train, y_val = Y_train_selected[train_ix], Y_train_selected[val_ix]\n",
    "\n",
    "    #Inner CV\n",
    "    cv_inner = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    model = SVC()\n",
    "    #define search space\n",
    "    param_grid = dict()\n",
    "    param_grid[\"C\"] = np.logspace(-18, 9, num=9, base=2).tolist() \n",
    "    param_grid[\"kernel\"] = [\"rbf\", \"linear\"] # \"poly\"\n",
    "    param_grid[\"gamma\"] = np.logspace(-18, 9, num=9, base=2).tolist() \n",
    "    search = GridSearchCV(model, param_grid, scoring=\"accuracy\", cv=cv_inner, refit=True, error_score=\"raise\")\n",
    "    result = search.fit(x_train, y_train) #runs fit with all sets of parameters\n",
    "    best_model = result.best_estimator_ #get the best performing model fit on the whole training set\n",
    "    yhat = best_model.predict(x_val) #evaluate model on the hold out dataset\n",
    "    acc_svm = accuracy_score(y_val, yhat) #evaluate the model\n",
    "    outer_results.append(acc_svm) #store result\n",
    "    print(\">acc=%.3f, est=%.3f, cfg=%s\" % (acc_svm, result.best_score_, result.best_params_))\n",
    "\n",
    "#summarize estimated performance of the model\n",
    "outer_results = np.array(outer_results)\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(outer_results), np.std(outer_results)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
